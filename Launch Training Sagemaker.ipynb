{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "apart-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-east-1-424632853466\n",
      "Prefix: sagemaker/MNIST_demo\n",
      "Region: us-east-1\n",
      "Job Name: training-pytorch\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "import os\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "boto_session = boto3.Session()\n",
    "sess = sagemaker.Session(boto_session)\n",
    "region = boto_session.region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket and prefix\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/MNIST_demo'\n",
    "job_name = 'training-pytorch'\n",
    "\n",
    "print(f'Bucket: {bucket}')\n",
    "print(f'Prefix: {prefix}')\n",
    "print(f'Region: {region}')\n",
    "print(f'Job Name: {job_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-flower",
   "metadata": {},
   "source": [
    "# Upload data to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "going-cargo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download MNIST data from torchvision\n",
    "datasets.MNIST('data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "employed-tribe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = sess.upload_data(path='data/MNIST/processed', bucket=bucket, key_prefix=prefix)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "distinct-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/output_run'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = f\"s3://{bucket}/{prefix}/output_run\"\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "naval-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/source_code'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_code_dir = f\"s3://{bucket}/{prefix}/source_code\"\n",
    "source_code_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-cannon",
   "metadata": {},
   "source": [
    "# Launch Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "gross-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-03 11:42:22 Starting - Starting the training job...\n",
      "2021-04-03 11:42:24 Starting - Launching requested ML instancesProfilerReport-1617450099: InProgress\n",
      "......\n",
      "2021-04-03 11:43:51 Starting - Preparing the instances for training...............\n",
      "2021-04-03 11:46:21 Downloading - Downloading input data\n",
      "2021-04-03 11:46:21 Training - Downloading the training image........................\n",
      "2021-04-03 11:50:22 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-04-03 11:50:09,873 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-04-03 11:50:09,897 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-04-03 11:50:12,919 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-04-03 11:50:14,428 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting mnist-demo@ git+https://github.com/benayas1/MNIST-deployment.git@478f3f8d9446fed3426a384d436e7f94cd1303e6\n",
      "  Cloning https://github.com/benayas1/MNIST-deployment.git (to revision 478f3f8d9446fed3426a384d436e7f94cd1303e6) to /tmp/pip-install-tb9kiqvi/mnist-demo_5b9aac75a342447b90043c0cc8a1e44a\u001b[0m\n",
      "\u001b[34mCollecting build==0.3.1.post1\n",
      "  Downloading build-0.3.1.post1-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses==0.8 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata==3.10.0\n",
      "  Downloading importlib_metadata-3.10.0-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging==20.9 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (20.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas==1.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.1.5)\u001b[0m\n",
      "\u001b[34mCollecting pep517==0.10.0\n",
      "  Downloading pep517-0.10.0-py2.py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow==8.1.2 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (8.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing==2.4.7 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil==2.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz==2021.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six==1.15.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting toml==0.10.2\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.8.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision==0.9.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions==3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp==3.4.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (3.4.1)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-inference\n",
      "  Downloading sagemaker_inference-1.5.5.tar.gz (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from sagemaker-inference->-r requirements.txt (line 19)) (5.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: retrying==1.3.3 in /opt/conda/lib/python3.6/site-packages (from sagemaker-inference->-r requirements.txt (line 19)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from sagemaker-inference->-r requirements.txt (line 19)) (1.5.4)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: mnist-demo, sagemaker-inference\n",
      "  Building wheel for mnist-demo (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for mnist-demo (setup.py): finished with status 'done'\n",
      "  Created wheel for mnist-demo: filename=mnist_demo-0.0.1-py3-none-any.whl size=2871 sha256=00b7d7ac8b28d505c7892b7bda8b244bc023beacd7117fba887a3224bc490068\n",
      "  Stored in directory: /root/.cache/pip/wheels/14/4b/cd/641a5d672ec0668813bb35113a675afd7323df6e2eda605749\n",
      "  Building wheel for sagemaker-inference (setup.py): started\n",
      "  Building wheel for sagemaker-inference (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-inference: filename=sagemaker_inference-1.5.5-py2.py3-none-any.whl size=26977 sha256=457f5922949cab1481234a53a1b5a4e60b78e9a5c034c09aea7cc7f6486af08c\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/bf/81/8e084e445a44e9fbc9d64efc7afb2a660ecd06285ea4a51fa0\u001b[0m\n",
      "\u001b[34mSuccessfully built mnist-demo sagemaker-inference\u001b[0m\n",
      "\u001b[34mInstalling collected packages: toml, numpy, importlib-metadata, pep517, sagemaker-inference, mnist-demo, build\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.3\n",
      "    Uninstalling importlib-metadata-3.7.3:\n",
      "      Successfully uninstalled importlib-metadata-3.7.3\u001b[0m\n",
      "\u001b[34mSuccessfully installed build-0.3.1.post1 importlib-metadata-3.10.0 mnist-demo-0.0.1 numpy-1.19.5 pep517-0.10.0 sagemaker-inference-1.5.5 toml-0.10.2\u001b[0m\n",
      "\u001b[34m  Running command git clone -q https://github.com/benayas1/MNIST-deployment.git /tmp/pip-install-tb9kiqvi/mnist-demo_5b9aac75a342447b90043c0cc8a1e44a\n",
      "  Running command git rev-parse -q --verify 'sha^478f3f8d9446fed3426a384d436e7f94cd1303e6'\n",
      "  Running command git fetch -q https://github.com/benayas1/MNIST-deployment.git 478f3f8d9446fed3426a384d436e7f94cd1303e6\n",
      "  Running command git checkout -q 478f3f8d9446fed3426a384d436e7f94cd1303e6\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-03 11:50:22,877 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 64,\n",
      "        \"epochs\": 7,\n",
      "        \"use_cuda\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2021-04-03-11-41-39-464\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/source_code/pytorch-training-2021-04-03-11-41-39-464/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":64,\"epochs\":7,\"use_cuda\":true}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/source_code/pytorch-training-2021-04-03-11-41-39-464/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":64,\"epochs\":7,\"use_cuda\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2021-04-03-11-41-39-464\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/source_code/pytorch-training-2021-04-03-11-41-39-464/source/sourcedir.tar.gz\",\"module_name\":\"train_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"64\",\"--epochs\",\"7\",\"--use_cuda\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=7\u001b[0m\n",
      "\u001b[34mSM_HP_USE_CUDA=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_sagemaker.py --batch_size 64 --epochs 7 --use_cuda True\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mSource /opt/ml/model\u001b[0m\n",
      "\u001b[34mChannel /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mDevice is cuda\u001b[0m\n",
      "\u001b[34mDownloading dataset from /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mDataset downloaded successfully\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.477 algo-1:70 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.606 algo-1:70 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.607 algo-1:70 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.607 algo-1:70 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.608 algo-1:70 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.608 algo-1:70 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.841 algo-1:70 INFO hook.py:584] name:conv1.weight count_params:288\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.841 algo-1:70 INFO hook.py:584] name:conv1.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.841 algo-1:70 INFO hook.py:584] name:conv2.weight count_params:18432\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:584] name:conv2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:584] name:fc1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:584] name:fc1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:584] name:fc2.weight count_params:1280\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:584] name:fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:586] Total Trainable Params: 1199882\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.842 algo-1:70 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-04-03 11:50:28.846 algo-1:70 INFO hook.py:476] Hook is writing from the hook with pid: 70\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/60000 (0%)]#011Loss: 2.300471\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [16000/60000 (27%)]#011Loss: 0.274713\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)]#011Loss: 0.182093\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [48000/60000 (80%)]#011Loss: 0.078082\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0507, Accuracy: 9837/10000 (98%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/60000 (0%)]#011Loss: 0.023461\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [16000/60000 (27%)]#011Loss: 0.022545\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [32000/60000 (53%)]#011Loss: 0.046604\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [48000/60000 (80%)]#011Loss: 0.037920\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0346, Accuracy: 9885/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/60000 (0%)]#011Loss: 0.115828\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [16000/60000 (27%)]#011Loss: 0.022727\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [32000/60000 (53%)]#011Loss: 0.029893\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [48000/60000 (80%)]#011Loss: 0.110928\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0352, Accuracy: 9889/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/60000 (0%)]#011Loss: 0.002515\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [16000/60000 (27%)]#011Loss: 0.044706\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [32000/60000 (53%)]#011Loss: 0.058162\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [48000/60000 (80%)]#011Loss: 0.030299\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0343, Accuracy: 9897/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/60000 (0%)]#011Loss: 0.123346\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [16000/60000 (27%)]#011Loss: 0.010246\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [32000/60000 (53%)]#011Loss: 0.004739\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [48000/60000 (80%)]#011Loss: 0.093140\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0295, Accuracy: 9909/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/60000 (0%)]#011Loss: 0.061680\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [16000/60000 (27%)]#011Loss: 0.003295\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [32000/60000 (53%)]#011Loss: 0.218463\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [48000/60000 (80%)]#011Loss: 0.004857\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0293, Accuracy: 9899/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/60000 (0%)]#011Loss: 0.006219\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [16000/60000 (27%)]#011Loss: 0.041899\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [32000/60000 (53%)]#011Loss: 0.014925\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [48000/60000 (80%)]#011Loss: 0.021928\u001b[0m\n",
      "\n",
      "2021-04-03 11:52:51 Uploading - Uploading generated training model\n",
      "2021-04-03 11:52:51 Completed - Training job completed\n",
      "\u001b[34mTest set: Average loss: 0.0290, Accuracy: 9906/10000 (99%)\n",
      "\u001b[0m\n",
      "\u001b[34mSaving model into /opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34m2021-04-03 11:52:42,723 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 410\n",
      "Billable seconds: 410\n"
     ]
    }
   ],
   "source": [
    "pytorch_estimator = PyTorch(entry_point='train_sagemaker.py',\n",
    "                            instance_type='ml.p2.xlarge',\n",
    "                            instance_count=1,\n",
    "                            framework_version='1.8.0', # 1.8.1 is not supported yet\n",
    "                            py_version='py3',\n",
    "                            role=role,\n",
    "                            source_dir='.', # local folder to be packed and used in entry point\n",
    "                            output_path=output_dir, # output parent folder in S3 to store everything generated\n",
    "                            #model_dir=model_dir,\n",
    "                            code_location= source_code_dir,\n",
    "                            #git_config={'repo':'', 'branch':'main'}, # git repo with the training script\n",
    "                            hyperparameters = {'epochs': 7, 'batch_size': 64, 'use_cuda': True })\n",
    "\n",
    "pytorch_estimator.fit({'training': train_data},\n",
    "                       #job_name=job_name\n",
    "                     ) # in this case we have just 1 data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "obvious-kuwait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/output_run/pytorch-training-2021-04-03-11-41-39-464/output/model.tar.gz'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    trained_model_file = pytorch_estimator.model_data # This is the S3 bucket URL with the trained model\n",
    "except:\n",
    "    trained_model_file = 's3://sagemaker-us-east-1-424632853466/sagemaker/MNIST_demo/output_run/pytorch-training-2021-04-02-20-34-43-399/output/model.tar.gz'\n",
    "trained_model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-aquatic",
   "metadata": {},
   "source": [
    "# Deploying the model\n",
    "Deploying a model can be done in two ways:  \n",
    "- From a model trained in sagemaker\n",
    "- From a model trained outside sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-jones",
   "metadata": {},
   "source": [
    "## From a model trained in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cognitive-singles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "# If the model is deployed from an Estimator object, then model_fn should be included in the training script\n",
    "predictor = pytorch_estimator.deploy(initial_instance_count=1,\n",
    "                                     instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-dylan",
   "metadata": {},
   "source": [
    "## From a model trained outside SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, an inference script should be provided. There is no need to add the model_fn function in the training script\n",
    "pytorch_model = sagemaker.pytorch.model.PyTorchModel(model_data=trained_model_file,\n",
    "                                                     role=role,\n",
    "                                                     framework_version='1.8.0', # 1.8.1 is not supported yet\n",
    "                                                     entry_point='inference_sagemaker_simple.py',\n",
    "                                                     py_version='py3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pytorch_model.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.m4.xlarge' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-irish",
   "metadata": {},
   "source": [
    "# Testing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "instrumental-electricity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data, _ = torch.load('data/MNIST/processed/test.pt')\n",
    "testing_data = testing_data.numpy()[:2]\n",
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "reported-eligibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('application/x-npy',)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "external-advice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.serializers.NumpySerializer at 0x7f02c969c160>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "level-ribbon",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from container model. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2021-04-03-11-53-08-554 in account 424632853466 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-64050fbea95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from model with message \"Your invocation timed out while waiting for a response from container model. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2021-04-03-11-53-08-554 in account 424632853466 for more information."
     ]
    }
   ],
   "source": [
    "predictor.predict(data=testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-bristol",
   "metadata": {},
   "source": [
    "# Delete Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "allied-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "recorded-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "\t\u001b[31mmodified:   requirements.txt\u001b[m\n",
      "\t\u001b[31mdeleted:    setup.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "\t\u001b[31mLaunch Training.ipynb\u001b[m\n",
      "\t\u001b[31mRecommendation System Using MXNET on AWS Sagemaker.ipynb\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31mrecommender.py\u001b[m\n",
      "\n",
      "no changes added to commit\n"
     ]
    }
   ],
   "source": [
    "!git commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "liked-picking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/MNIST-deployment\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-possibility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
